version: '3.8'

name: slate

services:
  # PostgreSQL Database for User Auth Service
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: userauth
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres" ]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # PostgreSQL Database for Assignment Grading Service
  assignment-grading-db:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: assignment_grading
    ports:
      - "5433:5432"
    volumes:
      - assignment-grading-data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres" ]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
  # PostgreSQL Database for Content Management Service
  postgres-cms:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: cms
      POSTGRES_PASSWORD: cms_password
      POSTGRES_DB: cms
    ports:
      - "5434:5432"
    volumes:
      - postgres-cms-data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U cms" ]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Redis for Rate Limiting and Job Queue
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 3s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
    restart: unless-stopped

  # MongoDB Database for Course Service
  mongodb:
    image: mongo:7-jammy
    container_name: slate-mongodb
    environment:
      MONGO_INITDB_DATABASE: courses
    ports:
      - "27017:27017"
    volumes:
      - mongodb-data:/data/db
    healthcheck:
      test: [ "CMD", "mongosh", "--eval", "db.adminCommand('ping')" ]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    restart: unless-stopped
  # MinIO for S3-compatible object storage
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 30s
      timeout: 20s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    restart: unless-stopped

  # ElasticSearch for content search
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    restart: unless-stopped

  # User Auth Service (Go)
  user-auth-service:
    build:
      context: .
      dockerfile: services/user-auth-service/Dockerfile
    environment:
      SERVER_HOST: "0.0.0.0"
      SERVER_PORT: "8081"
      DB_HOST: "postgres"
      DB_PORT: "5432"
      DB_USER: "postgres"
      DB_PASSWORD: "postgres"
      DB_NAME: "userauth"
      DB_SSLMODE: "disable"
      JWT_SECRET: "your-super-secret-jwt-key-change-in-production"
      JWT_ACCESS_TOKEN_DURATION: "15"
      JWT_REFRESH_TOKEN_DURATION: "168"
      GRPC_HOST: "0.0.0.0"
      GRPC_PORT: "50051"
      OTEL_EXPORTER_OTLP_ENDPOINT: "tempo:4317"
      REDIS_HOST: "redis"
      REDIS_PORT: "6379"
      RATE_LIMIT_ENABLED: "false" # Disabled for testing to avoid blocking e2e tests
      RATE_LIMIT_LOGIN_MAX: "1000"
      RATE_LIMIT_LOGIN_WINDOW: "60"
      RATE_LIMIT_REGISTER_MAX: "1000"
      RATE_LIMIT_REGISTER_WINDOW: "60"
      # Authentication Type Configuration
      # Valid values: normal, oauth, saml
      AUTH_TYPE: "normal"
      # OAuth 2.0 Mock Configuration for Testing
      OAUTH_GOOGLE_CLIENT_ID: "mock-google-client-id"
      OAUTH_GOOGLE_CLIENT_SECRET: "mock-google-client-secret"
      OAUTH_GOOGLE_REDIRECT_URI: "http://localhost:8080/auth/oauth/callback"
      OAUTH_GOOGLE_SCOPES: "openid,profile,email"
      # SAML 2.0 Mock Configuration for Testing
      SAML_SP_ENTITY_ID: "http://localhost:8080/saml/metadata"
      SAML_ACS_URL: "http://localhost:8080/auth/saml/acs"
      SAML_OKTA_ENTITY_ID: "http://mock-okta.example.com"
      SAML_OKTA_SSO_URL: "http://mock-okta.example.com/sso"
      SAML_OKTA_JIT_PROVISIONING: "true"
      SAML_OKTA_ORGANIZATION_ID: "test-org"
      # Database Connection Pool Configuration
      DB_MAX_OPEN_CONNS: "25" # Maximum number of open connections
      DB_MAX_IDLE_CONNS: "5" # Maximum number of idle connections
      DB_CONN_MAX_LIFETIME: "5m" # Maximum lifetime of a connection
      DB_CONN_MAX_IDLE_TIME: "1m" # Maximum idle time before closing
      # Logging Configuration
      LOG_LEVEL: "info" # Log level: debug, info, warn, error
      # Environment Configuration
      ENVIRONMENT: "development" # Environment: development, production (affects JWT secret validation)
    ports:
      - "50051:50051"
      - "8081:8081"
      - "9091:9090" # Prometheus metrics endpoint
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      tempo:
        condition: service_started
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
    restart: unless-stopped

  # Course Management Service (NestJS/MongoDB)
  course-service:
    build:
      context: .
      dockerfile: services/course-service/Dockerfile
    environment:
      NODE_ENV: "production"
      PORT: "3001"
      GRPC_HOST: "0.0.0.0"
      GRPC_PORT: "50052"
      MONGO_URI: "mongodb://mongodb:27017/courses"
      MONGO_DB_NAME: "courses"
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://tempo:4317"
      LOG_LEVEL: "info"
      METRICS_PORT: "9090"
      SERVICE_VERSION: "1.0.0"
      PROTO_PATH: "/app/proto/course.proto"
      PROTO_DIR: "/app/proto"
    ports:
      - "50052:50052" # gRPC
      - "3001:3001" # HTTP (health/metrics)
      - "9094:9090" # Prometheus metrics endpoint
    depends_on:
      mongodb:
        condition: service_healthy
      tempo:
        condition: service_started
  # Kafka (Message Broker)
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    ports:
      - "9097:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    restart: unless-stopped
  # Content Management Service (Rust)
  content-management-service:
    build:
      context: .
      dockerfile: services/content-management-service/Dockerfile
    environment:
      # Server Configuration
      SERVER__HOST: "0.0.0.0"
      SERVER__PORT: "8082"
      SERVER__GRPC_PORT: "50052"
      SERVER__METRICS_PORT: "9092"
      # Database Configuration
      DATABASE__URL: "postgresql://cms:cms_password@postgres-cms:5432/cms"
      DATABASE__MAX_CONNECTIONS: "20"
      DATABASE__MIN_CONNECTIONS: "5"
      # S3/MinIO Configuration
      S3__ENDPOINT: "http://minio:9000"
      S3__ACCESS_KEY: "minioadmin"
      S3__SECRET_KEY: "minioadmin"
      S3__BUCKET: "content-storage"
      S3__REGION: "us-east-1"
      # ElasticSearch Configuration
      ELASTICSEARCH__URL: "http://elasticsearch:9200"
      ELASTICSEARCH__INDEX: "content"
      # Redis Configuration
      REDIS__URL: "redis://redis:6379"
      REDIS__QUEUE_NAME: "transcoding_jobs"
      # Observability Configuration
      OBSERVABILITY__OTLP_ENDPOINT: "http://tempo:4317"
      OBSERVABILITY__SERVICE_NAME: "content-management-service"
      RUST_LOG: "info"
      # Analytics Service (placeholder - will be implemented later)
      # ANALYTICS_SERVICE_URL: "http://analytics-service:50053"
    ports:
      - "50055:50052"
      - "8082:8082"
      - "9096:9092"
    depends_on:
      postgres-cms:
        condition: service_healthy
      minio:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      redis:
        condition: service_healthy
      tempo:
        condition: service_started
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    restart: unless-stopped

  # Assignment Grading Service (Go)
  assignment-grading-service:
    build:
      context: .
      dockerfile: services/assignment-grading-service/Dockerfile
    environment:
      SERVER_HOST: "0.0.0.0"
      SERVER_PORT: "8083"
      DB_HOST: "assignment-grading-db"
      DB_PORT: "5432"
      DB_USER: "postgres"
      DB_PASSWORD: "postgres"
      DB_NAME: "assignment_grading"
      DB_SSLMODE: "disable"
      GRPC_HOST: "0.0.0.0"
      GRPC_PORT: "50053"
      KAFKA_ENABLED: "true"
      KAFKA_BROKERS: "kafka:9092"
      KAFKA_TOPIC: "assignment-events"
      STORAGE_TYPE: "local"
      STORAGE_LOCAL_PATH: "/app/storage"
      STORAGE_MAX_SIZE: "26214400"
      OTEL_EXPORTER_OTLP_ENDPOINT: "tempo:4317"
      LOG_LEVEL: "info"
      ENVIRONMENT: "development"
      DB_MAX_OPEN_CONNS: "25"
      DB_MAX_IDLE_CONNS: "5"
      DB_CONN_MAX_LIFETIME: "5m"
      DB_CONN_MAX_IDLE_TIME: "1m"
    ports:
      - "50053:50053"
      - "8083:8083"
      - "9093:9090" # Prometheus metrics endpoint
    volumes:
      - assignment-storage:/app/storage
    depends_on:
      assignment-grading-db:
        condition: service_healthy
      kafka:
        condition: service_started
      tempo:
        condition: service_started
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    restart: unless-stopped

  # API Gateway (Rust/Axum)
  api-gateway:
    build:
      context: .
      dockerfile: services/api-gateway/Dockerfile
    environment:
      # Logging configuration - supports per-module levels
      # Examples: "info", "debug", "info,api_gateway=debug,tower_http=warn"
      RUST_LOG: "info"
      GATEWAY_SERVER_HOST: "0.0.0.0"
      GATEWAY_SERVER_PORT: "8080"
      GATEWAY_AUTH_SERVICE_ENDPOINT: "http://user-auth-service:50051"
      GATEWAY_OBSERVABILITY_TEMPO_ENDPOINT: "http://tempo:4317"
      # Authentication Type Configuration
      # Should match the AUTH_TYPE configured in user-auth-service
      # Valid values: normal, oauth, saml
      AUTH_TYPE: "normal"
      # Request body size limits (DoS prevention)
      MAX_REQUEST_BODY_SIZE: "1048576" # 1MB default limit
      MAX_UPLOAD_BODY_SIZE: "26214400" # 25MB for upload endpoints (assignment submissions)
      UPLOAD_PATHS: "/upload,/api/upload,/api/assignments/*/submissions" # Comma-separated paths for upload limit
      # Trusted proxies for X-Forwarded-For header (comma-separated IPs)
      # TRUSTED_PROXIES: "10.0.0.1,172.17.0.1"  # Uncomment and set for production
    ports:
      - "8080:8080"
    volumes:
      - ./config/gateway-config.yaml:/app/config/gateway-config.yaml
      - ./services/api-gateway/openapi:/app/services/api-gateway/openapi
    depends_on:
      - prometheus
      - tempo
      - loki
      - grafana
      - user-auth-service
      - assignment-grading-service
      - content-management-service
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    restart: unless-stopped

  # Observability Stack
  prometheus:
    image: prom/prometheus
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    restart: unless-stopped

  tempo:
    image: grafana/tempo:latest
    command: [ "-config.file=/etc/tempo/tempo.yaml" ]
    volumes:
      - ./config/tempo.yaml:/etc/tempo/tempo.yaml
    ports:
      - "14268:14268" # jaeger ingest
      - "3200:3200" # tempo
      - "4317:4317" # otlp grpc
      - "4318:4318" # otlp http
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    restart: unless-stopped

  loki:
    image: grafana/loki:2.8.2
    command: "-config.file=/etc/loki/local-config.yaml"
    volumes:
      - ./config/loki.yaml:/etc/loki/local-config.yaml
      - loki-data:/loki
    ports:
      - "3100:3100"
    user: "root"
    environment:
      - PUID=1000
      - PGID=1000
    entrypoint:
      - sh
      - -c
      - |
        mkdir -p /loki/chunks /loki/index /loki/boltdb-cache /loki/compactor /loki/rules
        chown -R loki:loki /loki
        exec /usr/bin/loki -config.file=/etc/loki/local-config.yaml
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    volumes:
      - ./config/grafana-datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
      - tempo
      - loki
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
    restart: unless-stopped

  promtail:
    image: grafana/promtail:2.8.2
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/log:/var/log:ro
      - ./config/promtail-config.yaml:/etc/promtail/promtail-config.yaml
    command: -config.file=/etc/promtail/promtail-config.yaml
    depends_on:
      - loki
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 64M
    restart: unless-stopped

volumes:
  postgres-data:
    driver: local
  assignment-grading-data:
    driver: local
  assignment-storage:
    driver: local
  redis-data:
    driver: local
  mongodb-data:
    driver: local
  postgres-cms-data:
    driver: local
  minio-data:
    driver: local
  elasticsearch-data:
    driver: local
  loki-data:
    driver: local
